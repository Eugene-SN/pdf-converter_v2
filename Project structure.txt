Исходные данные по серверу: CPU 64 ядра, 2Тб RAM, 2x GPU A6000, Ubuntu 24.04 с предустановленными драйверами, CUDA 12.9 и всеми утилитами для работы с docker compose.

Проект по созданию расширенного комплексного решения для автоматизированного конвейера обработки китайских технических PDF документов, развернутое в едином docker compose. Основное требование - 100% соответствие полученных после конвертации и перевода markdown файлов исходным PDF по разметке, структуре и вложенным таблицам с изображениями. 

Необходимо учесть тип и состав конвертируемых pdf файлов: 
- цифровые pdf с текстовым векторным слоем; 
- pdf на китайском языке с техническими терминами и командами по управлению серверным оборудованием
- команды управления IPMI, BMC и код redfish должны быть извлечены без искажений и исключены из перевода

Предварительный вариант планируемой структуры нового проекта и основные отличия от текущего:
- замена движка Ollama на движок vLLM, запущенный в едином compose проекте;
- ВАЖНО!!! переход на модульную архитектуру с отдельными DAG для удобства развертывания и настройки, предварительно:
    - DAG 1: Document Preprocessing - чистое извлечение контента без потерь,
    - DAG 2: Content Transformation - преобразование в целевой формат,
    - DAG 3: Translation Pipeline - высококачественный перевод с сохранением структуры,
    - DAG 4: Quality Assurance - многоуровневая валидация и автокоррекция;
- замена модуля translator (в основе wolfreka/ollama-translator) на решение с OpenAI-совместимым vLLM-сервисом;
- этапы валидации дополненяются OCR-модулем для улучшения качества сравнения и исправления ошибок;
-замена компонентов проекта на более качественные и эффективные для достижения 100% соответствия с исходными PDF файлами результата конвертации и перевода, с полным сохранением структуры, заголовков, таблиц и разметки;
- расширенное логирование каждого этапа обработки, метрики производительности в реальном времени;
- внедрение OCR-валидации:
    - интеграция PaddleOCR + Tesseract для кросс-валидации;
    - алгоритм сравнения результатов OCR с текстовым слоем PDF;
    - автоматическое исправление расхождений;
    - проверка соответствия структуры документа;
    - валидация таблиц и их содержимого;
    - проверка корректности извлечения кода и спецсимволов;
    - cравнение AST исходного PDF и результирующего MD;
    - проверка соответствия заголовочной структуры;
    - валидация вложенных элементов (таблицы, списки, изображения);
- внедрение Visual diff системы:
    - улучшение diff-pdf для более точного сравнения;
    - внедрение SSIM + структурных метрик;
    - автоматическая коррекция на основе visual feedback;
- все скрипты запуска должны отображать хронологию выполнения задач, время выполнения и прогресс выполнения, отображая все параметры в виде строгого прогресс-бара, бех эмодзи.

Рассматриваются замены инструментов (необходимо проанализировать все инструменты и предложить наиболее качественный вариант, скорректировав список ниже):
- замена PDFPlumber на Docling для layout parsing;
- интеграция PaddleOCR как основного OCR движка (PaddleOCR + Tesseract для кросс-валидации и обработка pdf файлов в случае отсутствия текстового слоя);
- добавление Tabula-Py для улучшенного извлечения таблиц;
- внедрение Layout-Parser для структурного анализа;
- движок ollama на vllm, выбор моделей остается прежним (qwen2.5vl-32b и qwen3-32b)

Необходимо использовать папку на хосте для всех скачиваемых моделей и кэшей: для кэшей vLLM /mnt/storage/models/huggingface/, для любых иных моделей /mnt/storage/models/shared/.

Для каждого выходного md файла должна создаваться отдельная одноименная папка с подпапкой для изображений (с правами для чтения и записи 1000:1000) в директории, соответствующей скрипту действий (ниже описание).

Общая планируемая структура папок и файлов в проекте (при наличии дополнительных папок и файлов, которые не были учтены ниже - дополнить указанную структуру, предоставив новый вид):

/mnt/storage/docker/pdf-converter/ # папка НОВОГО проекта!
.
├── flask
│   ├── app.py
│   ├── dockerfile.flask
│   └── requirements-flask.txt
├── airflow/
│   ├── dags
│   │   ├── conversion.py
│   │   └── translation.py
│   ├── dockerfile.airflow
│   └── requirements-airflow.txt
├── diff-pdf
│   ├── compare_pdfs.py
│   └── dockerfile.diff-pdf
├── pandoc
│   ├── dockerfile.pandoc
│   ├── render_pdf.py
│   └── templates
│       └── chinese_tech.latex
├── translator
│   ├── config.py
│   ├── dockerfile.translator
│   ├── __pycache__
│   │   ├── config.cpython-310.pyc
│   │   └── translator.cpython-310.pyc
│   ├── pyproject.toml
│   ├── requirements.txt
│   └── translator.py
├── grafana
│   └── provisioning
│       ├── alerting
│       ├── dashboards
│       │   ├── dashboard.json
│       │   └── dashboard.yml
│       ├── datasources
│       │   └── prometheus.yml
│       └── plugins
├── prometheus
│   ├── prometheus.yml
│   └── statsd-mapping.yml
├── plugins
├── config
├── logs # все логи по работе сервисов сохраняются сюда
├── input_pdf
├── output_md_en
├── output_md_ru
├── output_md_zh
├── convert_md.sh # конвертирует pdf в md без перевода со 100% соответствием исходному pdf (папка сохранения output_md_zh), процесс конвертации с прогресс баром должен отображаться в терминале
├── translate_ru.sh # конвертирует pdf в md и переводит на русский (папка сохранения output_md_ru), процесс конвертации и перевода с прогресс баром должны отображаться в терминале
├── translate_en.sh # конвертирует pdf в md и переводит на английский (папка сохранения output_md_en), процесс конвертации и перевода с прогресс баром должны отображаться в терминале
├── translate_md_ru.sh # скрипт запуска перевода ollama-translator с флагом "ru" для перевода md из папки output_md_zh на русский (папка сохранения output_md_ru), процесс конвертации и перевода с прогресс баром должны отображаться в терминале
├── translate_md_ru.sh # скрипт запуска перевода ollama-translator с флагом "en" для перевода  md из папки output_md_zh на английский (папка сохранения output_md_en), процесс конвертации и перевода с прогресс баром должны отображаться в терминале
├── .env
├── docker-compose.yml # файл для ручного развертывания всех сервисов
├── install.sh # автоматизированная установка всего конвейера конвертации и перевода, все логи процесса установки должны отображаться в терминале
└── README.md # инструкция со всеми командами запуска и описанием структуры проекта


========== Ниже находится описание текущего развернутого решения с airflow оркестратором, на основе котороего будет создаваться и дорабатываться новый проект. ==========

Основные сервисы текущего решения:
-   Flask API
-   Apache Airflow
-   Ollama Translator Service # на базе скрипта wolfreka/ollama-translator
-   PostgreSQL
-   Redis   # брокер задач
-   Pandoc-Render   # контейнер с Pandoc/LaTeX для рендеринга Markdown→PDF
-   diff-pdf    # утилита для сравнения PDF
-   StatsD Exporter
-   Prometheus
-   Grafana

Все сервисы находятся в единой внешней сети ai-net. Ollama также находится в сети ai-net, уже развернута отдельным сервисом в другом docker compose.

Общий ориентировочный вид архитектуры проекта конвертации и перевода (при запуске только конвертации (convert_md.sh) исключаются модули: "Перевод" и "Вторая валидация"; при запуске скриптов перевода md (translate_md_ru.sh/translate_md_en.sh) используется только модуль "Перевод", при изапуске скриптов translate_ru.sh/translate_en.sh осуществляются все этапы с конвертацией, переводом и валидациями):

    %% Загрузка
    A[Пользователь через Flask API] --> B[Airflow Orchestrator]
    
    %% Разметка страницы
    B --> C1[VisionParse (LayoutParser+Detectron2/YOLO)]
    C1 --> C2[PDFPlumber (текст + координаты из VisionParse)]
    C2 --> C3[Camelot (точные таблицы по vision-bbox)]
    C3 --> C4[Сборка блоков text/table/image]
    
    %% Генерация Markdown
    C4 --> D1[LLM (Qwen2.5-VL, LangChain)]
    D1 --> D2[spaCy/SciSpaCy (headers, lists, code, NER)]
    D2 --> D3[RegEx-постпроцессинг (удаление артефактов, валидация MD)]
    
    %% Первая валидация
    D3 --> E1[MD → PDF Render (Pandoc, XeLaTeX)]
    E1 --> E2[Visual diff (diff-pdf, SSIM, structural check)]
    E2 --> E3[LLM анализ проблемных участков (Qwen2.5VL:32b)]
    E3 -->|auto-correct| D3
    
    %% Перевод
    D3 --> F0[Ollama Translator (qwen3:32b): zh → ru/en]
    F0 --> F1[RegEx-постпроцессинг (убрать порченую верстку, маркдаун-артефакты)]
    
    %% Вторая валидация (сравнение только структуры заголовкой, обзацев и таблиц, потому что китайский текст заменен на перевод)
    F1 --> G1[MD → PDF (Pandoc, XeLaTeX)]
    G1 --> G2[Visual diff (diff-pdf, SSIM, structural check)]
    G2 --> G3[LLM анализ проблемных участков (Qwen2.5VL:32b)]
    G3 -->|auto-correct| F1

    %% Выдача
    F1 --> H[Flask API<br/>(скачать готовый MD)]

Структура папок и файлов текущего запущенного конвейера для возможности анализа и понимания расположения вложенных файлов старого проекта:

root@ai:/mnt/storage/docker/pdf-translator# tree
.
├── airflow
│   ├── dockerfile.airflow
│   └── requirements-airflow.txt
├── config
├── convert_md.sh
├── dags
│   ├── pdf_to_md_dag.py
├── diff-pdf
│   ├── compare_pdfs.py
│   └── dockerfile.diff-pdf
├── docker-compose.yml
├── flask
│   ├── app.py
│   ├── dockerfile.flask
│   └── requirements-flask.txt
├── grafana
│   └── provisioning
│       ├── alerting
│       ├── dashboards
│       │   ├── dashboard.json
│       │   └── dashboard.yml
│       ├── datasources
│       │   └── prometheus.yml
│       └── plugins
├── input_pdf
├── install.sh
├── logs
├── output_md_en
├── output_md_ru
├── output_md_zh
├── pandoc
│   ├── dockerfile.pandoc
│   ├── render_pdf.py
│   └── templates
│       └── chinese_tech.latex
├── plugins
├── prometheus
│   ├── prometheus.yml
│   └── statsd-mapping.yml
├── translate_en.sh
├── translate_md_en.sh
├── translate_md_ru.sh
├── translate_ru.sh
├── translator
│   ├── config.py
│   ├── dockerfile.translator
│   ├── pyproject.toml
│   ├── requirements.txt
│   └── translator.py
└── README.md

=========================================================================================================================================================================


ВЫПОЛНЕНИЕ ПРОЕКТА МОЖНО РАЗДЕЛИТЬ НА НЕСКОЛЬКО ЭТАПОВ, СЛЕДУЮЩИХ ПОСЛЕ ГЛУБОКОГО АНАЛИЗА ВЛОЖЕННЫХ ФАЙЛОВ ДЕЙСТВУЮЩЕГО КОНВЕЙЕРА:
(расположение проекта по )

1) проверка кода всех файлов установки и запуска текущих сервисов и модулей оркестратора = ОСНОВА КОНВЕЙЕРА;
2) исправление и добавление/замена необходимых программ и сервисов, обновление docker compose файла с добавлением vLLM (все сервисы должны иметь стандартные порты);
3) продумать и описать возможную структуру последовательного запуска DAG скриптов, возможно функционально через скрипты или дополнительные DAG возможна реализация последовательного запуска групп DAG файлов, например: "Document Preprocessing->Content Transformation->Quality Assurance = обычная конвертация, Document Preprocessing->Content Transformation->Translation Pipeline->Quality Assurance = полный цикл конвертации и перевода";
4) последовательно создать все DAG файлы, в соответствии с запланированной модульностью проекта;
5) произвести финальную общую проверку всех компонентов и модулей вместе, включая мониторинг.

ОБЯЗАТЕЛЬНО!!! ТРЕБУЕТСЯ ПРИСЫЛАТЬ ГОТОВЫЕ ФАЙЛЫ, А ВСТАВКИ В КОДА В ТЕКСТОВОМ ВИДЕ ДЛЯ КОПИРОВАНИЯ!!! ПРИСЛАННЫЕ ФАЙЛЫ ДОЛЖНЫ ИСПОЛЬЗОВАТЬ СЛЕДУЮЩУЮ СХЕМУ НАИМЕНОВАНИЯ, ВКЛЮЧАЮЩУЮ ЧЕРЕЗ "_" УКАЗАНИЕ НА РАСПОЛОЖЕНИЕ В СТРУКТУРЕ ПРОЕКТА, РАЗМЕЩЕННОГО В ПАПКЕ /mnt/storage/docker/pdf-translator (например, translator_config.py, translator_translator.py, translator_dockerfile.translator, dags_pdf_to_md_dag.py, flask_dockerfile.flask, grafana_provisioning_dashboards_dashboard.json и т.д.); НЕЛЬЗЯ УПУСТИТЬ НИ ОДИН ФАЙЛ, ТРЕБУЕМЫЙ ДЛЯ РАЗВЕРТЫВАНИЯ КОНВЕЙЕРА!!!





Во вложении подробный файл с описанием требований по обновленному проекту конвертации технических цифровых pdf в md, включая опцию перевода, а также присутствует описание старого проекта и приложены основные файлы старого проекта - ВНИМАТЕЛЬНО И УГЛУБЛЕННО ИЗУЧИ ФАЙЛ "Project structure.txt"

Предлагаю в рамках текущего ответа проанализировать и оформить все процессы по новому проекту с подробным описанием каждого действия и предложенным исправлениям с дополнениям. После чего приступить к выполнению пунктов 1-3, описанных далее (пункты 4-5 будут выполняться в рамках следующих сообщений и запросов).

 ВЫПОЛНЕНИЕ ПРОЕКТА МОЖНО РАЗДЕЛИТЬ НА НЕСКОЛЬКО ЭТАПОВ, СЛЕДУЮЩИХ ПОСЛЕ ГЛУБОКОГО АНАЛИЗА ВЛОЖЕННЫХ ФАЙЛОВ ДЕЙСТВУЮЩЕГО КОНВЕЙЕРА:
(расположение проекта по )

1) проверка кода всех файлов установки и запуска текущих сервисов и модулей оркестратора = ОСНОВА КОНВЕЙЕРА;
2) исправление и добавление/замена необходимых программ и сервисов, обновление docker compose файла с добавлением vLLM (все сервисы должны иметь стандартные порты);
3) продумать и описать возможную структуру последовательного запуска DAG скриптов, возможно функционально через скрипты или дополнительные DAG возможна реализация последовательного запуска групп DAG файлов, например: "Document Preprocessing->Content Transformation->Quality Assurance = обычная конвертация, Document Preprocessing->Content Transformation->Translation Pipeline->Quality Assurance = полный цикл конвертации и перевода";
4) последовательно создать все DAG файлы, в соответствии с запланированной модульностью проекта;
5) произвести финальную общую проверку всех компонентов и модулей вместе, включая мониторинг.