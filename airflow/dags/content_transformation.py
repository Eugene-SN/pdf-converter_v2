#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
‚úÖ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù–ù–´–ô Content Transformation v3.0 - –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
–ü—Ä—è–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–ö–õ–Æ–ß–ï–í–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø:
- ‚úÖ –£–±—Ä–∞–Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
- ‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
- ‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- ‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.exceptions import AirflowException
import os
import json
import logging
import time
import re
from typing import Dict, Any, Optional, List

# –£—Ç–∏–ª–∏—Ç—ã
from shared_utils import (
    SharedUtils, NotificationUtils, ConfigUtils, 
    MetricsUtils, ErrorHandlingUtils
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DAG
DEFAULT_ARGS = {
    'owner': 'pdf-converter',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=3),
}

dag = DAG(
    'content_transformation',
    default_args=DEFAULT_ARGS,
    description='DAG 2: Content Transformation v3.0 - –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤',
    schedule_interval=None,
    max_active_runs=2,
    catchup=False,
    tags=['pdf-converter', 'dag2', 'transformation', 'chinese-docs', 'v3']
)

# ================================================================================
# –°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –î–õ–Ø –ö–ò–¢–ê–ô–°–ö–ò–• –î–û–ö–£–ú–ï–ù–¢–û–í
# ================================================================================

CHINESE_TRANSFORMATION_CONFIG = {
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∫–∏—Ç–∞–π—Å–∫–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    'heading_patterns': [
        r'^[Á¨¨Á´†ËäÇ]\s*[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ\d]+\s*[Á´†ËäÇ]',  # Á¨¨XÁ´†, Á¨¨XËäÇ
        r'^[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ]+[„ÄÅÔºé]',  # ‰∏≠ÊñáÊï∞Â≠ó
        r'^\d+[„ÄÅÔºé]\s*[\u4e00-\u9fff]',  # Êï∞Â≠ó + ‰∏≠Êñá
        r'^[\u4e00-\u9fff]+[:Ôºö]',  # ‰∏≠ÊñáÊ†áÈ¢òÂêéË∑üÂÜíÂè∑
    ],
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    'preserve_terms': {
        'ÈóÆÂ§©': 'WenTian',
        'ËÅîÊÉ≥ÈóÆÂ§©': 'Lenovo WenTian',
        'Â§©Êìé': 'ThinkSystem',
        'AnyBay': 'AnyBay',
        'Ëá≥Âº∫': 'Xeon',
        'ÂèØÊâ©Â±ïÂ§ÑÁêÜÂô®': 'Scalable Processors',
        'Ëã±ÁâπÂ∞î': 'Intel',
        'Â§ÑÁêÜÂô®': 'Processor',
        'ÂÜÖÊ†∏': 'Core',
        'Á∫øÁ®ã': 'Thread',
        'ÁùøÈ¢ë': 'Turbo Boost',
        'ÂÜÖÂ≠ò': 'Memory',
        'Â≠òÂÇ®': 'Storage',
        'Á°¨Áõò': 'Drive',
        'Âõ∫ÊÄÅÁ°¨Áõò': 'SSD',
        'Êú∫Ê¢∞Á°¨Áõò': 'HDD',
        'ÁÉ≠ÊèíÊãî': 'Hot-swap',
        'ÂÜó‰Ωô': 'Redundancy',
        'ËÉåÊùø': 'Backplane',
        'ÊâòÊû∂': 'Tray',
        '‰ª•Â§™ÁΩë': 'Ethernet',
        'ÂÖâÁ∫§': 'Fiber',
        'Â∏¶ÂÆΩ': 'Bandwidth',
        'Âª∂Ëøü': 'Latency',
        'ÁΩëÂç°': 'Network Adapter',
        'Ëã±ÂØ∏': 'inch',
        'Êú∫Êû∂': 'Rack',
        'ÊèíÊßΩ': 'Slot',
        'ËΩ¨Êé•Âç°': 'Riser Card',
        'ÁîµÊ∫ê': 'Power Supply',
        'ÈìÇÈáë': 'Platinum',
        'ÈíõÈáë': 'Titanium',
        'CRPS': 'CRPS'
    },
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    'quality_settings': {
        'preserve_chinese_structure': True,
        'enhance_technical_formatting': True,
        'improve_table_structure': True,
        'clean_whitespace': True
    }
}

# ================================================================================
# –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò
# ================================================================================

def load_intermediate_data(**context) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ç Stage 1"""
    start_time = time.time()
    
    try:
        dag_run_conf = context['dag_run'].conf or {}
        logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {json.dumps(dag_run_conf, indent=2, ensure_ascii=False)}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        intermediate_file = dag_run_conf.get('intermediate_file')
        if not intermediate_file or not os.path.exists(intermediate_file):
            raise ValueError(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {intermediate_file}")
        
        # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        with open(intermediate_file, 'r', encoding='utf-8') as f:
            document_data = json.load(f)
        
        if not document_data or 'markdown_content' not in document_data:
            raise ValueError("–î–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–µ—Å—Å–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        transformation_session = {
            'session_id': f"transform_{int(time.time())}",
            'document_data': document_data,
            'original_config': dag_run_conf.get('original_config', {}),
            'intermediate_file': intermediate_file,
            'chinese_document': dag_run_conf.get('chinese_document', True),
            'preserve_technical_terms': dag_run_conf.get('preserve_technical_terms', True),
            'transformation_start_time': datetime.now().isoformat()
        }
        
        content_length = len(document_data.get('markdown_content', ''))
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {content_length} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        
        MetricsUtils.record_processing_metrics(
            dag_id='content_transformation',
            task_id='load_intermediate_data',
            processing_time=time.time() - start_time,
            success=True
        )
        
        return transformation_session
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='content_transformation',
            task_id='load_intermediate_data',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise

def transform_chinese_content(**context) -> Dict[str, Any]:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –∫–∏—Ç–∞–π—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
    start_time = time.time()
    session = context['task_instance'].xcom_pull(task_ids='load_intermediate_data')
    
    try:
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        
        document_data = session['document_data']
        markdown_content = document_data.get('markdown_content', '')
        
        if not markdown_content.strip():
            raise ValueError("–ù–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        
        # ‚úÖ –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        transformed_content = apply_chinese_transformations(markdown_content)
        
        # ‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
        structured_content = improve_document_structure(transformed_content)
        
        # ‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        final_content = finalize_content_formatting(structured_content)
        
        # –†–∞—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        quality_score = calculate_transformation_quality(markdown_content, final_content)
        
        transformation_results = {
            'transformed_content': final_content,
            'original_length': len(markdown_content),
            'transformed_length': len(final_content),
            'quality_score': quality_score,
            'chinese_chars_preserved': count_chinese_characters(final_content),
            'technical_terms_preserved': count_preserved_terms(final_content),
            'transformation_stats': {
                'processing_time_seconds': time.time() - start_time,
                'transformation_method': 'chinese_optimized_v3',
                'content_improved': True
            }
        }
        
        MetricsUtils.record_processing_metrics(
            dag_id='content_transformation',
            task_id='transform_chinese_content',
            processing_time=time.time() - start_time,
            success=True
        )
        
        logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ö–∞—á–µ—Å—Ç–≤–æ: {quality_score:.1f}%")
        return transformation_results
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='content_transformation',
            task_id='transform_chinese_content',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
        raise

def apply_chinese_transformations(content: str) -> str:
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    try:
        # 1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        for chinese_term, english_term in CHINESE_TRANSFORMATION_CONFIG['preserve_terms'].items():
            if chinese_term in content:
                # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –∫–∏—Ç–∞–π—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
                content = content.replace(chinese_term, f"{chinese_term} ({english_term})")
        
        # 2. –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        content = improve_chinese_headings(content)
        
        # 3. –£–ª—É—á—à–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        content = enhance_chinese_tables(content)
        
        # 4. –û—á–∏—Å—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        content = clean_chinese_formatting(content)
        
        return content
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π: {e}")
        return content

def improve_chinese_headings(content: str) -> str:
    """–£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    try:
        lines = content.split('\n')
        improved_lines = []
        
        for line in lines:
            line_stripped = line.strip()
            if not line_stripped:
                improved_lines.append(line)
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–∏—Ç–∞–π—Å–∫–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            heading_level = detect_chinese_heading_level(line_stripped)
            
            if heading_level > 0 and not line_stripped.startswith('#'):
                # –î–æ–±–∞–≤–ª—è–µ–º markdown –∑–∞–≥–æ–ª–æ–≤–æ–∫
                markdown_prefix = '#' * heading_level + ' '
                improved_lines.append(f"{markdown_prefix}{line_stripped}")
            else:
                improved_lines.append(line)
        
        return '\n'.join(improved_lines)
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {e}")
        return content

def detect_chinese_heading_level(text: str) -> int:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    for pattern in CHINESE_TRANSFORMATION_CONFIG['heading_patterns']:
        if re.match(pattern, text):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
            if 'Á¨¨' in text and ('Á´†' in text):
                return 1  # –ì–ª–∞–≤—ã
            elif 'Á¨¨' in text and ('ËäÇ' in text):
                return 2  # –†–∞–∑–¥–µ–ª—ã
            elif re.match(r'^[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ]+[„ÄÅÔºé]', text):
                return 3  # –ü–æ–¥—Ä–∞–∑–¥–µ–ª—ã
            elif re.match(r'^\d+[„ÄÅÔºé]', text):
                return 2  # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã
            else:
                return 2  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    return 0  # –ù–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫

def enhance_chinese_tables(content: str) -> str:
    """–£–ª—É—á—à–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü —Å –∫–∏—Ç–∞–π—Å–∫–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º"""
    try:
        lines = content.split('\n')
        enhanced_lines = []
        in_table = False
        
        for i, line in enumerate(lines):
            if '|' in line and len([cell for cell in line.split('|') if cell.strip()]) >= 2:
                if not in_table:
                    # –ù–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã
                    in_table = True
                    enhanced_lines.append(line)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                    if (i + 1 < len(lines) and 
                        not re.match(r'^\|[\s\-:|]+\|', lines[i + 1])):
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                        cols = len([cell for cell in line.split('|') if cell.strip()])
                        separator = '|' + ' --- |' * cols
                        enhanced_lines.append(separator)
                else:
                    enhanced_lines.append(line)
            else:
                if in_table and line.strip() == '':
                    in_table = False
                enhanced_lines.append(line)
        
        return '\n'.join(enhanced_lines)
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
        return content

def clean_chinese_formatting(content: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    try:
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        content = re.sub(r'([\u4e00-\u9fff])\s+([\u4e00-\u9fff])', r'\1\2', content)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        content = re.sub(r'([\u4e00-\u9fff])\s*([Ôºå„ÄÇÔºõÔºöÔºÅÔºü])', r'\1\2', content)
        
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)
        
        # –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        lines = [line.rstrip() for line in content.split('\n')]
        content = '\n'.join(lines)
        
        return content.strip()
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return content

def improve_document_structure(content: str) -> str:
    """–£–ª—É—á—à–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        lines = content.split('\n')
        structured_lines = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º title –µ—Å–ª–∏ –Ω–µ—Ç
        has_title = any(line.strip().startswith('# ') for line in lines[:5])
        
        if not has_title and lines:
            # –ò—â–µ–º –ø–µ—Ä–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è –≤ title
            for i, line in enumerate(lines[:10]):
                if line.strip() and not line.startswith('#'):
                    structured_lines.append(f"# {line.strip()}")
                    lines[i] = ""  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
                    break
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
        for line in lines:
            if line.strip():
                structured_lines.append(line)
            else:
                structured_lines.append(line)
        
        return '\n'.join(structured_lines)
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
        return content

def finalize_content_formatting(content: str) -> str:
    """–§–∏–Ω–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    try:
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        content = content.strip()
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –∫–æ–Ω—Ü–µ —Ä–∞–∑–¥–µ–ª–æ–≤
        content = re.sub(r'(\n#+.*?)\n\n+', r'\1\n\n', content)
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        content = re.sub(r'(#+\s+.*?)\n([^\n])', r'\1\n\n\2', content)
        
        return content
        
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return content

def calculate_transformation_quality(original: str, transformed: str) -> float:
    """–†–∞—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    try:
        quality_score = 100.0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã (–Ω–µ –¥–æ–ª–∂–Ω–∞ —Å–∏–ª—å–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)
        length_ratio = len(transformed) / max(len(original), 1)
        if length_ratio < 0.8 or length_ratio > 1.3:
            quality_score -= 10
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        original_headers = len(re.findall(r'^#+\s', original, re.MULTILINE))
        transformed_headers = len(re.findall(r'^#+\s', transformed, re.MULTILINE))
        
        if transformed_headers < original_headers:
            quality_score -= 15
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü
        original_tables = len(re.findall(r'\|.*\|', original))
        transformed_tables = len(re.findall(r'\|.*\|', transformed))
        
        if original_tables > 0:
            table_preservation = transformed_tables / original_tables
            if table_preservation < 0.9:
                quality_score -= 10
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        original_chinese = count_chinese_characters(original)
        transformed_chinese = count_chinese_characters(transformed)
        
        if original_chinese > 0:
            chinese_preservation = transformed_chinese / original_chinese
            if chinese_preservation < 0.9:
                quality_score -= 20
        
        return max(0, quality_score)
        
    except Exception:
        return 75.0  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

def count_chinese_characters(text: str) -> int:
    """–ü–æ–¥—Å—á–µ—Ç –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    return len(re.findall(r'[\u4e00-\u9fff]', text))

def count_preserved_terms(text: str) -> int:
    """–ü–æ–¥—Å—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
    count = 0
    for term in CHINESE_TRANSFORMATION_CONFIG['preserve_terms'].values():
        count += text.count(term)
    return count

def save_transformation_result(**context) -> Dict[str, Any]:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    start_time = time.time()
    
    try:
        session = context['task_instance'].xcom_pull(task_ids='load_intermediate_data')
        transformation_results = context['task_instance'].xcom_pull(task_ids='transform_chinese_content')
        
        original_config = session['original_config']
        timestamp = original_config.get('timestamp', int(time.time()))
        filename = original_config.get('filename', 'unknown.pdf')
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–∫–∏—Ç–∞–π—Å–∫–∏–π —è–∑—ã–∫ - –∏—Å—Ç–æ—á–Ω–∏–∫)
        output_dir = f"/app/output/zh"
        os.makedirs(output_dir, exist_ok=True)
        
        markdown_filename = f"{timestamp}_{filename.replace('.pdf', '.md')}"
        output_path = f"{output_dir}/{markdown_filename}"
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(transformation_results['transformed_content'])
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è Stage 3
        stage3_config = {
            'markdown_file': output_path,
            'markdown_content': transformation_results['transformed_content'],
            'original_config': original_config,
            'stage2_completed': True,
            'transformation_metadata': {
                'quality_score': transformation_results['quality_score'],
                'transformation_method': 'chinese_optimized_v3',
                'chinese_chars_preserved': transformation_results['chinese_chars_preserved'],
                'technical_terms_preserved': transformation_results['technical_terms_preserved'],
                'completion_time': datetime.now().isoformat()
            }
        }
        
        MetricsUtils.record_processing_metrics(
            dag_id='content_transformation',
            task_id='save_transformation_result',
            processing_time=time.time() - start_time,
            success=True
        )
        
        logger.info(f"üíæ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        return stage3_config
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='content_transformation',
            task_id='save_transformation_result',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
        raise

def notify_transformation_completion(**context) -> None:
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    try:
        stage3_config = context['task_instance'].xcom_pull(task_ids='save_transformation_result')
        transformation_metadata = stage3_config['transformation_metadata']
        
        quality_score = transformation_metadata['quality_score']
        chinese_chars = transformation_metadata['chinese_chars_preserved']
        tech_terms = transformation_metadata['technical_terms_preserved']
        
        message = f"""
‚úÖ CONTENT TRANSFORMATION –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û

üìÑ –§–∞–π–ª: {stage3_config['markdown_file']}
üéØ –ö–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {quality_score:.1f}%
üà∂ –ö–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤: {chinese_chars}
üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {tech_terms}
üìä –ú–µ—Ç–æ–¥: {transformation_metadata['transformation_method']}

‚úÖ –ì–æ—Ç–æ–≤ –∫ –ø–µ—Ä–µ–¥–∞—á–µ –Ω–∞ Stage 3 (Translation Pipeline)
        """
        
        logger.info(message)
        NotificationUtils.send_success_notification(context, stage3_config)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")

# ================================================================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–î–ê–ß
# ================================================================================

# –ó–∞–¥–∞—á–∞ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
load_data = PythonOperator(
    task_id='load_intermediate_data',
    python_callable=load_intermediate_data,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 2: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
transform_content = PythonOperator(
    task_id='transform_chinese_content',
    python_callable=transform_chinese_content,
    execution_timeout=timedelta(minutes=15),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
save_result = PythonOperator(
    task_id='save_transformation_result',
    python_callable=save_transformation_result,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 4: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
notify_completion = PythonOperator(
    task_id='notify_transformation_completion',
    python_callable=notify_transformation_completion,
    trigger_rule='all_done',
    execution_timeout=timedelta(minutes=2),
    dag=dag
)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
load_data >> transform_content >> save_result >> notify_completion

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
def handle_transformation_failure(context):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    try:
        failed_task = context['task_instance'].task_id
        exception = context.get('exception')
        
        error_message = f"""
üî• –û–®–ò–ë–ö–ê –í CONTENT TRANSFORMATION

–ó–∞–¥–∞—á–∞: {failed_task}
–û—à–∏–±–∫–∞: {str(exception) if exception else 'Unknown'}

–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:
1. –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
2. –ü—Ä–æ–±–ª–µ–º—ã —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
3. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –ø–∞–º—è—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
4. –û—à–∏–±–∫–∏ –≤ –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è—Ö

–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ –∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        
        logger.error(error_message)
        NotificationUtils.send_failure_notification(context, exception)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –æ—à–∏–±–æ–∫: {e}")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫ –∫–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º
for task in dag.tasks:
    task.on_failure_callback = handle_transformation_failure