#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
‚úÖ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù–ù–´–ô DAG: Document Preprocessing - –ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
–í–ï–†–°–ò–Ø 3.0 - Production-ready —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö PDF

–ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø:
- ‚úÖ Airflow —Ç–æ–ª—å–∫–æ –∫–∞–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
- ‚úÖ –í—Å—è –ª–æ–≥–∏–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ —ç—Ç–æ–º DAG
- ‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- ‚úÖ –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Docling –±–µ–∑ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
- ‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –Ω–æ –º–æ—â–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.exceptions import AirflowException
import os
import json
import logging
import time
from typing import Dict, Any, Optional
from pathlib import Path

# –ü—Ä—è–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–±–µ–∑ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤)
try:
    from docling.document_converter import DocumentConverter, PdfFormatOption
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    DOCLING_AVAILABLE = True
except ImportError:
    DOCLING_AVAILABLE = False
    logging.warning("Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É—é fallback –æ–±—Ä–∞–±–æ—Ç–∫—É")

# –£—Ç–∏–ª–∏—Ç—ã
from shared_utils import (
    SharedUtils, NotificationUtils, ConfigUtils, 
    MetricsUtils, ErrorHandlingUtils
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DAG
DEFAULT_ARGS = {
    'owner': 'pdf-converter',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=3),
}

dag = DAG(
    'document_preprocessing',  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏–º—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä—É
    default_args=DEFAULT_ARGS,
    description='DAG 1: –ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF –≤ Markdown –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤',
    schedule_interval=None,
    max_active_runs=3,
    catchup=False,
    tags=['pdf-converter', 'dag1', 'chinese-docs', 'production']
)

# ================================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –î–õ–Ø –ö–ò–¢–ê–ô–°–ö–ò–• –î–û–ö–£–ú–ï–ù–¢–û–í
# ================================================================================

# –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
CHINESE_DOC_CONFIG = {
    # OCR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
    'ocr_languages': 'chi_sim,chi_tra,eng',  # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –∫–∏—Ç–∞–π—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
    'ocr_confidence_threshold': 0.75,  # –ü–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    'chinese_header_patterns': [
        r'^[Á¨¨Á´†ËäÇ]\s*[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ\d]+\s*[Á´†ËäÇ]',  # Á¨¨XÁ´†, Á¨¨XËäÇ
        r'^[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ]+[„ÄÅÔºé]',  # –ö–∏—Ç–∞–π—Å–∫–∏–µ —á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ
        r'^\d+[„ÄÅÔºé]\s*[\u4e00-\u9fff]',  # –ê—Ä–∞–±—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã + –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
    ],
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è (–ù–ï –ü–ï–†–ï–í–û–î–ò–¢–¨)
    'tech_terms': {
        'ÈóÆÂ§©': 'WenTian',
        'ËÅîÊÉ≥ÈóÆÂ§©': 'Lenovo WenTian', 
        'Â§©Êìé': 'ThinkSystem',
        'Ëá≥Âº∫': 'Xeon',
        'ÂèØÊâ©Â±ïÂ§ÑÁêÜÂô®': 'Scalable Processors',
        'Ëã±ÁâπÂ∞î': 'Intel',
        'Â§ÑÁêÜÂô®': 'Processor',
        'ÂÜÖÊ†∏': 'Core',
        'Á∫øÁ®ã': 'Thread',
        'ÂÜÖÂ≠ò': 'Memory',
        'Â≠òÂÇ®': 'Storage',
        '‰ª•Â§™ÁΩë': 'Ethernet',
        'Êú∫Êû∂': 'Rack',
        'ÊèíÊßΩ': 'Slot',
        'ÁîµÊ∫ê': 'Power Supply'
    },
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö PDF
    'quality_settings': {
        'dpi': 300,  # –í—ã—Å–æ–∫–æ–µ DPI –¥–ª—è —á–µ—Ç–∫–∏—Ö –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        'enable_table_detection': True,
        'preserve_chinese_formatting': True,
        'enhance_chinese_text': True
    }
}

# ================================================================================
# –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò
# ================================================================================

def validate_input_file(**context) -> Dict[str, Any]:
    """‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    start_time = time.time()
    
    try:
        dag_run_conf = context['dag_run'].conf or {}
        logger.info(f"üìã –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {json.dumps(dag_run_conf, indent=2, ensure_ascii=False)}")
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        required_params = ['input_file', 'filename', 'timestamp', 'master_run_id']
        missing_params = [param for param in required_params if not dag_run_conf.get(param)]
        
        if missing_params:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {missing_params}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
        input_file = dag_run_conf['input_file']
        if not SharedUtils.validate_input_file(input_file):
            raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª: {input_file}")
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        file_info = analyze_chinese_document(input_file)
        
        # –û–±–æ–≥–∞—â–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        enriched_config = {
            **dag_run_conf,
            **file_info,
            'chinese_doc_analysis': file_info,
            'processing_mode': 'chinese_optimized',
            'validation_timestamp': datetime.now().isoformat()
        }
        
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id='validate_input_file',
            processing_time=time.time() - start_time,
            success=True
        )
        
        logger.info(f"‚úÖ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω: {dag_run_conf['filename']}")
        return enriched_config
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id='validate_input_file', 
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise

def analyze_chinese_document(file_path: str) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        file_size = os.path.getsize(file_path)
        file_hash = SharedUtils.calculate_file_hash(file_path)
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–µ—Å–ª–∏ PDF —á–∏—Ç–∞–µ—Ç—Å—è)
        has_chinese_text = False
        estimated_pages = 0
        
        try:
            # –ü—Ä–æ–±—É–µ–º –±—ã—Å—Ç—Ä–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞
            import fitz  # PyMuPDF –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            doc = fitz.open(file_path)
            estimated_pages = doc.page_count
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            for page_num in range(min(3, doc.page_count)):
                page = doc[page_num]
                text = page.get_text()[:1000]  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
                chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
                if chinese_chars > 10:  # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª–µ–µ 10 –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    has_chinese_text = True
                    break
            
            doc.close()
            
        except Exception:
            # Fallback –∞–Ω–∞–ª–∏–∑ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞
            estimated_pages = max(1, file_size // 102400)  # ~100KB –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
        
        return {
            'file_hash': file_hash,
            'file_size_bytes': file_size,
            'file_size_mb': file_size / (1024 * 1024),
            'estimated_pages': estimated_pages,
            'has_chinese_text': has_chinese_text,
            'recommended_ocr': not has_chinese_text,  # OCR –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è
            'processing_complexity': 'high' if file_size > 50*1024*1024 else 'medium'
        }
        
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç: {e}")
        return {
            'file_hash': 'unknown',
            'file_size_bytes': 0,
            'file_size_mb': 0.0,
            'estimated_pages': 1,
            'has_chinese_text': True,  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∫–∏—Ç–∞–π—Å–∫–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            'recommended_ocr': True,
            'processing_complexity': 'medium'
        }

def process_document_with_docling(**context) -> Dict[str, Any]:
    """‚úÖ –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ Docling —Å –∫–∏—Ç–∞–π—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
    start_time = time.time()
    config = context['task_instance'].xcom_pull(task_ids='validate_input_file')
    
    try:
        input_file = config['input_file']
        timestamp = config['timestamp']
        filename = config['filename']
        
        logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {filename}")
        
        if not DOCLING_AVAILABLE:
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ
            return process_document_fallback(input_file, config)
        
        # ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Docling –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        pipeline_options = PdfPipelineOptions()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ OCR
        use_ocr = config.get('enable_ocr', config['chinese_doc_analysis']['recommended_ocr'])
        pipeline_options.do_ocr = use_ocr
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        pipeline_options.do_table_structure = True  # –í–∞–∂–Ω–æ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        pipeline_options.generate_page_images = config.get('extract_images', True)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
        converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º Docling –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä (OCR: {'–≤–∫–ª—é—á–µ–Ω' if use_ocr else '–æ—Ç–∫–ª—é—á–µ–Ω'})")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        result = converter.convert(input_file)
        document = result.document
        
        # ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –∫–∏—Ç–∞–π—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        markdown_content = document.export_to_markdown()
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        processed_markdown = post_process_chinese_markdown(markdown_content)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        temp_dir = f"/app/temp"
        os.makedirs(temp_dir, exist_ok=True)
        intermediate_file = f"{temp_dir}/preprocessing_{timestamp}.json"
        
        document_data = {
            'title': getattr(document, 'title', '') or filename.replace('.pdf', ''),
            'pages_count': len(document.pages) if hasattr(document, 'pages') else 1,
            'markdown_content': processed_markdown,
            'raw_text': processed_markdown,  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            'metadata': {
                'original_file': input_file,
                'processing_timestamp': timestamp,
                'docling_version': '2.0+',
                'ocr_enabled': use_ocr,
                'chinese_optimized': True,
                'processing_mode': config['processing_mode']
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        with open(intermediate_file, 'w', encoding='utf-8') as f:
            json.dump(document_data, f, ensure_ascii=False, indent=2)
        
        processing_time = time.time() - start_time
        
        result = {
            'success': True,
            'document_info': {
                'title': document_data['title'],
                'total_pages': document_data['pages_count'],
                'processing_time': processing_time,
                'status': 'success'
            },
            'intermediate_file': intermediate_file,
            'original_config': config,
            'processing_stats': {
                'pages_processed': document_data['pages_count'],
                'ocr_used': use_ocr,
                'processing_time_seconds': processing_time,
                'chinese_chars_found': count_chinese_characters(processed_markdown)
            }
        }
        
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id='process_document_with_docling',
            processing_time=processing_time,
            pages_count=document_data['pages_count'],
            success=True
        )
        
        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {processing_time:.2f}—Å")
        return result
        
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id='process_document_with_docling',
            processing_time=time.time() - start_time,
            success=False
        )
        
        return {
            'success': False,
            'error': error_msg,
            'original_config': config
        }

def process_document_fallback(input_file: str, config: Dict[str, Any]) -> Dict[str, Any]:
    """Fallback –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ Docling"""
    try:
        logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –æ–±—Ä–∞–±–æ—Ç–∫—É (Docling –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        markdown_content = f"# {config['filename'].replace('.pdf', '')}\n\n"
        markdown_content += "–î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ fallback —Ä–µ–∂–∏–º–µ.\n\n"
        markdown_content += f"–§–∞–π–ª: {config['filename']}\n"
        markdown_content += f"–†–∞–∑–º–µ—Ä: {config['chinese_doc_analysis']['file_size_mb']:.2f} MB\n"
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        temp_dir = "/app/temp"
        os.makedirs(temp_dir, exist_ok=True)
        intermediate_file = f"{temp_dir}/preprocessing_{config['timestamp']}.json"
        
        document_data = {
            'title': config['filename'].replace('.pdf', ''),
            'pages_count': config['chinese_doc_analysis']['estimated_pages'],
            'markdown_content': markdown_content,
            'raw_text': markdown_content,
            'metadata': {
                'fallback_mode': True,
                'processing_timestamp': config['timestamp']
            }
        }
        
        with open(intermediate_file, 'w', encoding='utf-8') as f:
            json.dump(document_data, f, ensure_ascii=False, indent=2)
        
        return {
            'success': True,
            'document_info': {
                'title': document_data['title'],
                'total_pages': document_data['pages_count'],
                'processing_time': 1.0,
                'status': 'fallback_success'
            },
            'intermediate_file': intermediate_file,
            'original_config': config,
            'processing_stats': {
                'fallback_mode': True,
                'processing_time_seconds': 1.0
            }
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': f"Fallback –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {str(e)}",
            'original_config': config
        }

def post_process_chinese_markdown(markdown: str) -> str:
    """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ Markdown –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        for chinese_term, english_term in CHINESE_DOC_CONFIG['tech_terms'].items():
            if chinese_term in markdown:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                markdown = markdown.replace(chinese_term, f"{chinese_term} ({english_term})")
        
        # –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        lines = markdown.split('\n')
        processed_lines = []
        
        for line in lines:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∏—Ç–∞–π—Å–∫–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            for pattern in CHINESE_DOC_CONFIG['chinese_header_patterns']:
                import re
                if re.match(pattern, line.strip()):
                    if not line.strip().startswith('#'):
                        line = f"## {line.strip()}"
                    break
            
            processed_lines.append(line)
        
        # –£–ª—É—á—à–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        processed_markdown = '\n'.join(processed_lines)
        processed_markdown = improve_chinese_tables(processed_markdown)
        
        return processed_markdown
        
    except Exception as e:
        logger.warning(f"–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ markdown –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        return markdown

def improve_chinese_tables(markdown: str) -> str:
    """–£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü —Å –∫–∏—Ç–∞–π—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º"""
    try:
        import re
        
        # –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü –∏ —É–ª—É—á—à–µ–Ω–∏–µ –∏—Ö —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        lines = markdown.split('\n')
        improved_lines = []
        in_table = False
        
        for line in lines:
            if '|' in line and len(line.split('|')) >= 3:
                if not in_table:
                    # –ù–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã - –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                    in_table = True
                    if not any(c in line for c in ['---', '===', '-+-']):
                        improved_lines.append(line)
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
                        cols = len([col for col in line.split('|') if col.strip()])
                        separator = '|' + '---|' * max(1, cols-2) + '|'
                        improved_lines.append(separator)
                        continue
                improved_lines.append(line)
            else:
                if in_table and line.strip() == '':
                    in_table = False
                improved_lines.append(line)
        
        return '\n'.join(improved_lines)
        
    except Exception as e:
        logger.warning(f"–£–ª—É—á—à–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        return markdown

def count_chinese_characters(text: str) -> int:
    """–ü–æ–¥—Å—á–µ—Ç –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
    try:
        return sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    except:
        return 0

def prepare_for_next_stage(**context) -> Dict[str, Any]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ DAG"""
    start_time = time.time()
    
    try:
        result = context['task_instance'].xcom_pull(task_ids='process_document_with_docling')
        
        if not result.get('success'):
            raise AirflowException(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {result.get('error')}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        intermediate_file = result.get('intermediate_file')
        if not intermediate_file or not os.path.exists(intermediate_file):
            raise AirflowException("–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è DAG2
        next_stage_config = {
            'intermediate_file': intermediate_file,
            'original_config': result['original_config'],
            'dag1_metadata': {
                **result.get('processing_stats', {}),
                'completion_time': datetime.now().isoformat()
            },
            'dag1_completed': True,
            'ready_for_transformation': True,
            'chinese_document': True  # –§–ª–∞–≥ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç–∞–¥–∏–π
        }
        
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id='prepare_for_next_stage',
            processing_time=time.time() - start_time,
            success=True
        )
        
        logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ DAG")
        return next_stage_config
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id='prepare_for_next_stage',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise

def notify_completion(**context) -> None:
    """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        result = context['task_instance'].xcom_pull(task_ids='process_document_with_docling')
        next_config = context['task_instance'].xcom_pull(task_ids='prepare_for_next_stage')
        
        if result and result.get('success'):
            stats = result.get('processing_stats', {})
            message = f"""
‚úÖ DOCUMENT PREPROCESSING –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û

üìÑ –§–∞–π–ª: {result['original_config']['filename']}
üìä –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats.get('pages_processed', 'N/A')}
‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats.get('processing_time_seconds', 0):.2f}—Å
üîç OCR –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {'–î–∞' if stats.get('ocr_used') else '–ù–µ—Ç'}
üà∂ –ö–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats.get('chinese_chars_found', 0)}
üéØ –†–µ–∂–∏–º: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

üìÅ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª: {next_config.get('intermediate_file', 'N/A')}

‚úÖ –ì–æ—Ç–æ–≤ –∫ –ø–µ—Ä–µ–¥–∞—á–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç–∞–¥–∏—é
            """
            
            NotificationUtils.send_success_notification(context, result)
        else:
            error = result.get('error', 'Unknown error') if result else 'No result'
            message = f"""
‚ùå DOCUMENT PREPROCESSING –ó–ê–í–ï–†–®–ï–ù –° –û–®–ò–ë–ö–û–ô

üìÑ –§–∞–π–ª: {result['original_config']['filename'] if result else 'Unknown'}
‚ùå –û—à–∏–±–∫–∞: {error}
‚è∞ –í—Ä–µ–º—è: {datetime.now().isoformat()}

–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
            """
            NotificationUtils.send_failure_notification(context, Exception(error))
        
        logger.info(message)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")

# ================================================================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–î–ê–ß
# ================================================================================

# –ó–∞–¥–∞—á–∞ 1: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
validate_input = PythonOperator(
    task_id='validate_input_file',
    python_callable=validate_input_file,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 2: –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
process_document = PythonOperator(
    task_id='process_document_with_docling',
    python_callable=process_document_with_docling,
    execution_timeout=timedelta(hours=1),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ DAG
prepare_next = PythonOperator(
    task_id='prepare_for_next_stage',
    python_callable=prepare_for_next_stage,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 4: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
notify_task = PythonOperator(
    task_id='notify_completion',
    python_callable=notify_completion,
    trigger_rule='all_done',
    execution_timeout=timedelta(minutes=2),
    dag=dag
)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
validate_input >> process_document >> prepare_next >> notify_task

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
def handle_processing_failure(context):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        failed_task = context['task_instance'].task_id
        exception = context.get('exception')
        
        error_message = f"""
üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í DOCUMENT PREPROCESSING

–ó–∞–¥–∞—á–∞: {failed_task}
–û—à–∏–±–∫–∞: {str(exception) if exception else 'Unknown'}

–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:
1. –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π PDF —Ñ–∞–π–ª
2. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
3. –ü—Ä–æ–±–ª–µ–º—ã —Å Docling –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π
4. –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å PDF —Ñ–∞–π–ª–∞
- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        """
        
        logger.error(error_message)
        NotificationUtils.send_failure_notification(context, exception)
        
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing',
            task_id=failed_task,
            processing_time=0,
            success=False
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –æ—à–∏–±–æ–∫: {e}")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫ –∫–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º
for task in dag.tasks:
    task.on_failure_callback = handle_processing_failure