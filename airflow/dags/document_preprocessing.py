#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô DAG 1: Document Preprocessing via Microservice Architecture
–í–ï–†–°–ò–Ø 2.0 - –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é

–£–õ–£–ß–®–ï–ù–ò–Ø:
- ‚úÖ –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —á–µ—Ä–µ–∑ HTTP API
- ‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å retry –∏ exponential backoff
- ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
- ‚úÖ –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
- ‚úÖ Timeout –∏ SLA –∫–æ–Ω—Ç—Ä–æ–ª—å
- ‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∏ performance tracking
- ‚úÖ –ì–∏–±–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- ‚úÖ Circuit breaker –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from airflow.exceptions import AirflowException
import os
import json
import logging
import time
import requests
from typing import Dict, Any, Optional
from pathlib import Path
from pydantic import BaseModel, ValidationError
import hashlib
from functools import wraps

# –ò–º–ø–æ—Ä—Ç —É—Ç–∏–ª–∏—Ç
from shared_utils import (
    SharedUtils, NotificationUtils, ConfigUtils, 
    VLLMUtils, MetricsUtils, ErrorHandlingUtils
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ‚úÖ –ù–û–í–û–ï: Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ API –æ—Ç–≤–µ—Ç–æ–≤
class DocumentInfo(BaseModel):
    title: str
    total_pages: int
    processing_time: float
    status: str
    file_size_mb: Optional[float] = None
    content_hash: Optional[str] = None

class ProcessingStats(BaseModel):
    pages_processed: int
    ocr_used: bool
    processing_time_seconds: float
    tables_found: Optional[int] = 0
    images_found: Optional[int] = 0
    extraction_quality_score: Optional[float] = None

class DocumentProcessorResponse(BaseModel):
    success: bool
    document_info: Optional[DocumentInfo] = None
    intermediate_file: Optional[str] = None
    processing_stats: Optional[ProcessingStats] = None
    error: Optional[str] = None
    service_version: Optional[str] = None
    processing_id: Optional[str] = None

# ‚úÖ –ù–û–í–û–ï: –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è retry —Å exponential backoff
def retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0, max_delay: float = 60.0):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    
                    delay = min(base_delay * (2 ** attempt), max_delay)
                    logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞: {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay}—Å")
                    time.sleep(delay)
            return None
        return wrapper
    return decorator

# ‚úÖ –ù–û–í–û–ï: Circuit breaker –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –æ—Ç–∫–∞–∑–æ–≤
class CircuitBreaker:
    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
    
    def call(self, func, *args, **kwargs):
        if self.state == 'OPEN':
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = 'HALF_OPEN'
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = func(*args, **kwargs)
            self.reset()
            return result
        except Exception as e:
            self.record_failure()
            raise e
    
    def reset(self):
        self.failure_count = 0
        self.state = 'CLOSED'
        self.last_failure_time = None
    
    def record_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = 'OPEN'

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π circuit breaker –¥–ª—è document-processor
doc_processor_cb = CircuitBreaker()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DAG
DEFAULT_ARGS = {
    'owner': 'pdf-converter',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=2),
    'retry_exponential_backoff': True,
    'max_retry_delay': timedelta(minutes=10),
    'sla': timedelta(hours=2),  # ‚úÖ –ù–û–í–û–ï: SLA –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
}

dag = DAG(
    'document_preprocessing_v2',
    default_args=DEFAULT_ARGS,
    description='DAG 1: Document Preprocessing via Microservice Architecture v2.0',
    schedule_interval=None,
    max_active_runs=5,  # ‚úÖ –£–í–ï–õ–ò–ß–ï–ù–û: –±–æ–ª—å—à–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
    catchup=False,
    tags=['pdf-converter', 'dag1', 'microservices', 'v2.0']
)

def validate_dag1_input(**context) -> Dict[str, Any]:
    """‚úÖ –£–õ–£–ß–®–ï–ù–û: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    start_time = time.time()
    
    try:
        dag_run_conf = context['dag_run'].conf or {}
        logger.info(f"üîç DAG1: –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {json.dumps(dag_run_conf, indent=2)}")
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        required_params = ['input_file', 'filename', 'timestamp', 'master_run_id']
        missing_params = [param for param in required_params if not dag_run_conf.get(param)]
        
        if missing_params:
            raise ValueError(f"DAG1: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {missing_params}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ SharedUtils
        input_file = dag_run_conf['input_file']
        if not SharedUtils.validate_input_file(input_file):
            raise ValueError(f"DAG1: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª: {input_file}")
        
        # ‚úÖ –ù–û–í–û–ï: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        file_info = SharedUtils.calculate_file_hash(input_file)
        file_size = os.path.getsize(input_file)
        
        # –û–±–æ–≥–∞—â–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        enriched_config = {
            **dag_run_conf,
            'file_hash': file_info,
            'file_size_bytes': file_size,
            'file_size_mb': file_size / (1024 * 1024),
            'validation_timestamp': datetime.now().isoformat(),
            'dag_version': '2.0'
        }
        
        # ‚úÖ –ù–û–í–û–ï: –ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='validate_dag1_input',
            processing_time=time.time() - start_time,
            success=True
        )
        
        logger.info(f"‚úÖ DAG1: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Ñ–∞–π–ª–∞: {dag_run_conf['filename']} "
                   f"({enriched_config['file_size_mb']:.2f} MB, hash: {file_info[:8]}...)")
        
        return enriched_config
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='validate_dag1_input',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå DAG1: –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise

@retry_with_backoff(max_retries=3, base_delay=2.0, max_delay=30.0)
def call_document_processor_service(request_data: Dict[str, Any]) -> requests.Response:
    """‚úÖ –ù–û–í–û–ï: –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è HTTP-–≤—ã–∑–æ–≤–∞ —Å retry"""
    processor_url = os.getenv('DOCUMENT_PROCESSOR_URL', 'http://document-processor:8001')
    api_key = os.getenv('DOC_PROCESSOR_API_KEY')
    timeout = int(os.getenv('PROCESSING_TIMEOUT_MINUTES', '60')) * 60
    
    headers = {
        'Content-Type': 'application/json',
        'User-Agent': 'Airflow-DAG-v2.0'
    }
    
    # ‚úÖ –ù–û–í–û–ï: –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
    if api_key:
        headers['Authorization'] = f'Bearer {api_key}'
    
    logger.info(f"üîÑ DAG1: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ {processor_url}/process")
    logger.debug(f"Request data: {json.dumps(request_data, indent=2)}")
    
    response = requests.post(
        f"{processor_url}/process",
        json=request_data,
        headers=headers,
        timeout=timeout
    )
    
    return response

def process_document_via_microservice(**context) -> Dict[str, Any]:
    """‚úÖ –£–õ–£–ß–®–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    start_time = time.time()
    dag_config = context['task_instance'].xcom_pull(task_ids='validate_dag1_input')
    
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
        request_data = {
            'input_file': dag_config['input_file'],
            'filename': dag_config['filename'],
            'enable_ocr': dag_config.get('enable_ocr', False),
            'extract_tables': dag_config.get('extract_tables', True),
            'extract_images': dag_config.get('extract_images', True),
            'ocr_languages': dag_config.get('ocr_languages', 'eng'),
            'quality_level': dag_config.get('quality_level', 'high'),
            'timestamp': dag_config['timestamp'],
            'file_hash': dag_config['file_hash'],
            'request_id': f"dag1_{dag_config['master_run_id']}_{int(time.time())}"
        }
        
        # ‚úÖ –ù–û–í–û–ï: Circuit breaker –∑–∞—â–∏—Ç–∞
        response = doc_processor_cb.call(call_document_processor_service, request_data)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ HTTP —Å—Ç–∞—Ç—É—Å–∞
        if response.status_code != 200:
            error_msg = f"document-processor –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}: {response.text}"
            logger.error(f"‚ùå DAG1: {error_msg}")
            
            return {
                'success': False,
                'error': error_msg,
                'http_status': response.status_code,
                'original_config': dag_config
            }
        
        # ‚úÖ –ù–û–í–û–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ Pydantic
        try:
            response_data = response.json()
            validated_response = DocumentProcessorResponse(**response_data)
        except (json.JSONDecodeError, ValidationError) as e:
            error_msg = f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç document-processor: {e}"
            logger.error(f"‚ùå DAG1: {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'original_config': dag_config
            }
        
        if not validated_response.success:
            logger.error(f"‚ùå DAG1: document-processor —Å–æ–æ–±—â–∏–ª –æ–± –æ—à–∏–±–∫–µ: {validated_response.error}")
            return {
                'success': False,
                'error': validated_response.error,
                'original_config': dag_config
            }
        
        # ‚úÖ –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if validated_response.intermediate_file:
            if not os.path.exists(validated_response.intermediate_file):
                error_msg = f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {validated_response.intermediate_file}"
                logger.error(f"‚ùå DAG1: {error_msg}")
                return {
                    'success': False,
                    'error': error_msg,
                    'original_config': dag_config
                }
        
        processing_time = time.time() - start_time
        
        # ‚úÖ –ù–û–í–û–ï: –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if validated_response.processing_stats:
            MetricsUtils.record_processing_metrics(
                dag_id='document_preprocessing_v2',
                task_id='process_document_via_microservice',
                processing_time=processing_time,
                pages_count=validated_response.processing_stats.pages_processed,
                success=True
            )
        
        result = {
            'success': True,
            'document_info': validated_response.document_info.dict() if validated_response.document_info else {},
            'intermediate_file': validated_response.intermediate_file,
            'original_config': dag_config,
            'processing_stats': validated_response.processing_stats.dict() if validated_response.processing_stats else {},
            'service_metadata': {
                'service_version': validated_response.service_version,
                'processing_id': validated_response.processing_id,
                'total_processing_time': processing_time
            }
        }
        
        logger.info(f"‚úÖ DAG1: –î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {processing_time:.2f}—Å")
        return result
        
    except requests.Timeout:
        error_msg = "Timeout –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ document-processor"
        logger.error(f"‚ùå DAG1: {error_msg}")
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='process_document_via_microservice',
            processing_time=time.time() - start_time,
            success=False
        )
        return {
            'success': False,
            'error': error_msg,
            'error_type': 'timeout',
            'original_config': dag_config
        }
    
    except requests.ConnectionError:
        error_msg = "–ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ document-processor"
        logger.error(f"‚ùå DAG1: {error_msg}")
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='process_document_via_microservice',
            processing_time=time.time() - start_time,
            success=False
        )
        return {
            'success': False,
            'error': error_msg,
            'error_type': 'connection_error',
            'original_config': dag_config
        }
    
    except Exception as e:
        error_msg = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ document-processor: {str(e)}"
        logger.error(f"‚ùå DAG1: {error_msg}")
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='process_document_via_microservice',
            processing_time=time.time() - start_time,
            success=False
        )
        return {
            'success': False,
            'error': error_msg,
            'error_type': 'unexpected_error',
            'original_config': dag_config
        }

def prepare_for_dag2(**context) -> Dict[str, Any]:
    """‚úÖ –£–õ–£–ß–®–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DAG2 —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
    start_time = time.time()
    
    try:
        dag1_result = context['task_instance'].xcom_pull(task_ids='process_document_via_microservice')
        
        if not dag1_result.get('success'):
            error_details = {
                'error': dag1_result.get('error', 'Unknown error'),
                'error_type': dag1_result.get('error_type', 'unknown'),
                'http_status': dag1_result.get('http_status')
            }
            raise AirflowException(f"DAG1 –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {error_details}")
        
        # ‚úÖ –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        intermediate_file = dag1_result.get('intermediate_file')
        if intermediate_file:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —á–∏—Ç–∞–µ–º—ã–π –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–π JSON
            try:
                data = SharedUtils.load_intermediate_result(intermediate_file)
                if not data:
                    raise ValueError("–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω")
            except Exception as e:
                raise AirflowException(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è DAG2
        dag2_config = {
            'intermediate_file': intermediate_file,
            'original_config': dag1_result['original_config'],
            'dag1_metadata': {
                **dag1_result.get('processing_stats', {}),
                **dag1_result.get('service_metadata', {}),
                'dag1_completion_time': datetime.now().isoformat()
            },
            'dag1_completed': True,
            'ready_for_transformation': True,
            'dag_version': '2.0'
        }
        
        # ‚úÖ –ù–û–í–û–ï: –ú–µ—Ç—Ä–∏–∫–∏
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='prepare_for_dag2',
            processing_time=time.time() - start_time,
            success=True
        )
        
        logger.info(f"‚úÖ DAG1‚ÜíDAG2: –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        logger.info(f"üìÑ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª: {dag2_config['intermediate_file']}")
        logger.debug(f"DAG2 config: {json.dumps(dag2_config, indent=2, default=str)}")
        
        return dag2_config
        
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='prepare_for_dag2',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå DAG1: –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DAG2: {e}")
        raise

def notify_dag1_completion(**context) -> None:
    """‚úÖ –£–õ–£–ß–®–ï–ù–û: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
    try:
        dag1_result = context['task_instance'].xcom_pull(task_ids='process_document_via_microservice')
        dag2_config = context['task_instance'].xcom_pull(task_ids='prepare_for_dag2')
        
        if dag1_result and dag1_result.get('success'):
            stats = dag1_result.get('processing_stats', {})
            doc_info = dag1_result.get('document_info', {})
            service_meta = dag1_result.get('service_metadata', {})
            
            message = f"""
‚úÖ DAG 1: DOCUMENT PREPROCESSING –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û (v2.0)

üìÑ –§–∞–π–ª: {dag1_result['original_config']['filename']}
üìä –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats.get('pages_processed', 'N/A')}
‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {service_meta.get('total_processing_time', 0):.2f}—Å
üîç OCR –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {'–î–∞' if stats.get('ocr_used') else '–ù–µ—Ç'}
üìã –¢–∞–±–ª–∏—Ü –Ω–∞–π–¥–µ–Ω–æ: {stats.get('tables_found', 'N/A')}
üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {stats.get('images_found', 'N/A')}
‚≠ê –ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {stats.get('extraction_quality_score', 'N/A')}
üè∑Ô∏è –í–µ—Ä—Å–∏—è —Å–µ—Ä–≤–∏—Å–∞: {service_meta.get('service_version', 'N/A')}
üÜî ID –æ–±—Ä–∞–±–æ—Ç–∫–∏: {service_meta.get('processing_id', 'N/A')}

üîÑ –ì–û–¢–û–í –ö –ü–ï–†–ï–î–ê–ß–ï –í DAG2 (Content Transformation)
üìÅ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª: {dag2_config.get('intermediate_file', 'N/A')}

‚úÖ –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
            """
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± —É—Å–ø–µ—Ö–µ
            NotificationUtils.send_dag_completion_notification(context, dag1_result)
            
        else:
            error = dag1_result.get('error', 'Unknown error') if dag1_result else 'No result received'
            error_type = dag1_result.get('error_type', 'unknown') if dag1_result else 'unknown'
            
            message = f"""
‚ùå DAG 1: DOCUMENT PREPROCESSING –ó–ê–í–ï–†–®–ï–ù –° –û–®–ò–ë–ö–û–ô (v2.0)

üìÑ –§–∞–π–ª: {dag1_result['original_config']['filename'] if dag1_result else 'N/A'}
‚ùå –û—à–∏–±–∫–∞: {error}
üè∑Ô∏è –¢–∏–ø –æ—à–∏–±–∫–∏: {error_type}
‚è∞ –í—Ä–µ–º—è: {datetime.now().isoformat()}

üîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å document-processor —Å–µ—Ä–≤–∏—Å–∞
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–µ—Ç–∏ –∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            """
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
            error_obj = Exception(error) if dag1_result else Exception("No result from processing")
            NotificationUtils.send_failure_notification(context, error_obj)
        
        logger.info(message)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")

# ‚úÖ –ù–û–í–û–ï: –ó–∞–¥–∞—á–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
def check_microservices_health(**context) -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤"""
    start_time = time.time()
    
    try:
        processor_url = os.getenv('DOCUMENT_PROCESSOR_URL', 'http://document-processor:8001')
        vllm_config = ConfigUtils.get_vllm_config()
        
        health_status = {
            'document_processor': False,
            'vllm_server': False,
            'all_healthy': False
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ document-processor
        try:
            response = requests.get(f"{processor_url}/health", timeout=10)
            health_status['document_processor'] = response.status_code == 200
        except:
            pass
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ vLLM (–¥–ª—è –±—É–¥—É—â–∏—Ö DAG)
        health_status['vllm_server'] = VLLMUtils.check_vllm_health(
            vllm_config['server_url'], timeout=10
        )
        
        health_status['all_healthy'] = all(health_status.values())
        
        if not health_status['all_healthy']:
            logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–µ—Ä–≤–∏—Å—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {health_status}")
        else:
            logger.info("‚úÖ –í—Å–µ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã –¥–æ—Å—Ç—É–ø–Ω—ã")
        
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='check_microservices_health',
            processing_time=time.time() - start_time,
            success=health_status['all_healthy']
        )
        
        return health_status
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–æ–≤: {e}")
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id='check_microservices_health',
            processing_time=time.time() - start_time,
            success=False
        )
        raise

# ‚úÖ –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–î–ê–ß DAG v2.0

# –ó–∞–¥–∞—á–∞ 0: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
health_check = PythonOperator(
    task_id='check_microservices_health',
    python_callable=check_microservices_health,
    execution_timeout=timedelta(minutes=2),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 1: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
validate_input = PythonOperator(
    task_id='validate_dag1_input',
    python_callable=validate_dag1_input,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å
process_document = PythonOperator(
    task_id='process_document_via_microservice',
    python_callable=process_document_via_microservice,
    execution_timeout=timedelta(hours=2),  # ‚úÖ –ù–û–í–û–ï: Timeout –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DAG2
prepare_dag2 = PythonOperator(
    task_id='prepare_for_dag2',
    python_callable=prepare_for_dag2,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# –ó–∞–¥–∞—á–∞ 4: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
notify_completion = PythonOperator(
    task_id='notify_dag1_completion',
    python_callable=notify_dag1_completion,
    trigger_rule='all_done',  # ‚úÖ –ù–û–í–û–ï: –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
    execution_timeout=timedelta(minutes=2),
    dag=dag
)

# ‚úÖ –ù–û–í–û–ï: –ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def cleanup_temp_files(**context) -> None:
    """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        temp_dir = os.getenv('TEMP_DIR', '/app/temp')
        max_age_hours = int(os.getenv('TEMP_FILES_MAX_AGE_HOURS', '24'))
        
        cleaned_count = SharedUtils.cleanup_temp_files(temp_dir, max_age_hours)
        logger.info(f"üßπ –û—á–∏—â–µ–Ω–æ {cleaned_count} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ä—à–µ {max_age_hours} —á–∞—Å–æ–≤")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

cleanup_files = PythonOperator(
    task_id='cleanup_temp_files',
    python_callable=cleanup_temp_files,
    trigger_rule='all_done',
    execution_timeout=timedelta(minutes=5),
    dag=dag
)

# ‚úÖ –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô v2.0
health_check >> validate_input >> process_document >> prepare_dag2
[prepare_dag2, process_document] >> notify_completion
notify_completion >> cleanup_files

# ‚úÖ –£–õ–£–ß–®–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
def handle_dag1_failure(context):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ DAG1"""
    try:
        failed_task = context['task_instance'].task_id
        exception = context.get('exception')
        dag_run_conf = context.get('dag_run', {}).conf or {}
        
        error_details = ErrorHandlingUtils.handle_dag_error(context, 
            f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ {failed_task}")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        diagnostic_info = {
            'task_id': failed_task,
            'error_type': type(exception).__name__ if exception else 'Unknown',
            'file_processed': dag_run_conf.get('filename', 'Unknown'),
            'dag_version': '2.0',
            'circuit_breaker_state': doc_processor_cb.state,
            'failure_count': doc_processor_cb.failure_count
        }
        
        error_message = f"""
üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í DAG 1 v2.0: DOCUMENT PREPROCESSING

üìã –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:
‚Ä¢ –ó–∞–¥–∞—á–∞: {failed_task}
‚Ä¢ –û—à–∏–±–∫–∞: {str(exception) if exception else 'Unknown'}
‚Ä¢ –§–∞–π–ª: {diagnostic_info['file_processed']}
‚Ä¢ Circuit Breaker: {diagnostic_info['circuit_breaker_state']}

üîß –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –∏ —Ä–µ—à–µ–Ω–∏—è:
1. document-processor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
2. –ü—Ä–µ–≤—ã—à–µ–Ω timeout –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Üí —É–≤–µ–ª–∏—á—å—Ç–µ –ª–∏–º–∏—Ç—ã –∏–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ
3. –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª ‚Üí –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏ —Ä–∞–∑–º–µ—Ä
4. –ü—Ä–æ–±–ª–µ–º—ã —Å–µ—Ç–∏ ‚Üí –ø—Ä–æ–≤–µ—Ä—å—Ç–µ connectivity –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
5. –ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ ‚Üí –ø—Ä–æ–≤–µ—Ä—å—Ç–µ memory/CPU usage

üìä –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
{json.dumps(diagnostic_info, indent=2)}
        """
        
        logger.error(error_message)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
        NotificationUtils.send_failure_notification(context, exception)
        
        # ‚úÖ –ù–û–í–û–ï: –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—à–∏–±–æ–∫
        MetricsUtils.record_processing_metrics(
            dag_id='document_preprocessing_v2',
            task_id=failed_task,
            processing_time=0,
            success=False
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –æ—à–∏–±–æ–∫: {e}")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫ –∫–æ –≤—Å–µ–º –∑–∞–¥–∞—á–∞–º
for task in dag.tasks:
    task.on_failure_callback = handle_dag1_failure